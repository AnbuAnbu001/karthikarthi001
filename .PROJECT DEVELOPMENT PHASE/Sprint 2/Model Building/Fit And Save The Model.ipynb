{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db4a8f1",
   "metadata": {},
   "source": [
    "\n",
    "**Image Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb46b7",
   "metadata": {},
   "source": [
    "**Import ImageDataGenerator Library And Configure It**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8b76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbf210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed0063",
   "metadata": {},
   "source": [
    "**Apply ImageDataGenerator Functionality To Train And Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ea4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"C:\\Users\\Acer\\Downloads\\conversation engine for deaf and dumb\\Dataset\\training_set\",target_size=(64,64),\n",
    "                                          class_mode=\"categorical\",batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8c87f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r\"C:\\Users\\Acer\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set\",target_size=(64,64),\n",
    "                                                            class_mode=\"categorical\",batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0aaf0",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089d9d9",
   "metadata": {},
   "source": [
    "**Import The Required Model Building Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9477ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc32b5",
   "metadata": {},
   "source": [
    "**Initialize The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89394e00",
   "metadata": {},
   "source": [
    "**Add The Convolution Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cd435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
    "#No of feature detectors, size of feature detector, image size, activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95305d4e",
   "metadata": {},
   "source": [
    "**Add The Pooling Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ee8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785169ae",
   "metadata": {},
   "source": [
    "**Add The Flatten Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ad486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede3c43",
   "metadata": {},
   "source": [
    "**Adding The Dense Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e4f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8094f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ffc163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1355aeb",
   "metadata": {},
   "source": [
    "**Compile The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860295ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1de30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fd8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbb580",
   "metadata": {},
   "source": [
    "**Fit And Save The Model**\n",
    "Fit the neural network model with the train and test set, number of epochs, and validation steps.\n",
    "The weights are to be saved for future use. The weights are saved in signlanguage.h5 file using save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1fd4ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "525/525 [==============================] - 329s 616ms/step - loss: 0.3160 - accuracy: 0.8886 - val_loss: 0.1389 - val_accuracy: 0.9644\n",
      "Epoch 2/9\n",
      "525/525 [==============================] - 251s 478ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.2418 - val_accuracy: 0.9662\n",
      "Epoch 3/9\n",
      "525/525 [==============================] - 271s 515ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 0.2308 - val_accuracy: 0.9680\n",
      "Epoch 4/9\n",
      "525/525 [==============================] - 240s 457ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.1640 - val_accuracy: 0.9711\n",
      "Epoch 5/9\n",
      "525/525 [==============================] - 217s 412ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0888 - val_accuracy: 0.9769\n",
      "Epoch 6/9\n",
      "525/525 [==============================] - 267s 509ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.2250 - val_accuracy: 0.9782\n",
      "Epoch 7/9\n",
      "525/525 [==============================] - 344s 655ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1629 - val_accuracy: 0.9773\n",
      "Epoch 8/9\n",
      "525/525 [==============================] - 356s 678ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1430 - val_accuracy: 0.9631\n",
      "Epoch 9/9\n",
      "525/525 [==============================] - 363s 692ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.2175 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231bd228e20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,epochs=9,validation_data=x_test,steps_per_epoch=len(x_train),validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda941b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"signlanguage-new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d89e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
